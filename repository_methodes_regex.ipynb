{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center> Utilisation des Regex <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sommaire: \n",
    "1. [Introduction](#introduction)\n",
    "2. [Suppression des caractères](#suppressioncaractères)\n",
    "3. [Extraction des caractères](#extractioncaractères)\n",
    "4. [Correction des chaines de caractères](#correction)\n",
    "5. [Regex spécifiques avec re.search](#regexspecifiques)\n",
    "6. [Autres exemples](#divers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Introduction** <a id='introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "Ce notebook présente en détail des cas d'utilisation des expressions régulières dans l'optique de supprimmer ou extraire des éléments d'une chaine de caractère dans le language Pytrhon. \n",
    "Pour aller plus loin sur le fonctionnement des regex, je recommande les deux excellents tutoriels sur le sujet proposé par le site Real Python \n",
    "<a href=\"https://realpython.com/regex-python/\">https://realpython.com/regex-python/</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook nous utiliserons ce texte ci-dessous pour illustrer les possibilités d'utiliation des regex. <hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import string\n",
    "sample_text = \"Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions \\\n",
    "régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement \\\n",
    "automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi \\\n",
    "que les chiffres par exemple 100$ ($100) ou 90€ (€90) . \\\n",
    "Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). \\\n",
    "A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] \\\n",
    "lorsque l'on souhaite nettoyer des chaines de caractère le + vite. \\\n",
    "Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. \\\n",
    "En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) \\\n",
    "sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Suppression de caractère spécifiques** <a id='suppressioncaractères'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supprimmer des lettres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1m Suppression des lettres tout en gardant les nombres \u001b[0m\n",
      " 100 100 90 90 18 10 2020 1 2 \n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1m Suppression des lettres tout en gardant les nombres \\033[0m')\n",
    "text =  re.sub('\\D',' ', sample_text) #non digit\n",
    "text =  re.sub('\\s+',' ', text) #extraspace\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Supprimer des chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des nombres et remplacement du caractère par un espace blanc\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple $ ($) ou € (€) . Il suffit de combiner les règles pour arriver à ses fins . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le //, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp, j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La ière version était pédagogique, la ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print(\"\\033[1mSuppression des nombres et remplacement du caractère par un espace blanc\\033[0m\")\n",
    "text = re.sub('\\d+', '', sample_text)\n",
    "text =  re.sub('\\s+',' ', text) #extraspace\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des nombres ayant des unités attachées ($,€ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des nombres seuls et ainsi que unités attachées ($,€,..;)\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple  () ou  () . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le  vite. Depuis le //, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   ière version était pédagogique, la ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "print(\"\\033[1mSuppression des nombres seuls et ainsi que unités attachées ($,€,..;)\\033[0m\")\n",
    "text = re.sub(r'[\\€|\\$\\d+]','', sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des nombres en combinaison avec certains éléments\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La    version était pédagogique, la  version du livre est tout aussi fantastique.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSuppression des nombres en combinaison avec certains éléments\\033[0m')\n",
    "\n",
    "text = re.sub(r'(\\d+)(er|ier|ière|ième)','', sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Suppression des lettres et des nombres pour ne garder que les caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des lettres et des nombres pour ne garder que les caractères spéciaux\u001b[0m\n",
      " ' ' # ( ). $ ($) € (€) . . ' ! ;-). ' # ( ), [] ' + . //, ://./ .. , , ' (@ ( .@.) ../. , .\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des lettres et des nombres pour ne garder que les caractères spéciaux. Les caractères avec les accents apparaissent dans les résultats\u001b[0m\n",
      " ' ' é éè # ( ). éè é $ ($) € (€) . è à . ' ! ;-). é 'ê #é à ( ), [] ' è + . //, ://./ .. è, , ' ç (@ ( ç.@.) ../. è é é, è .\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print(\"\\033[1mSuppression des lettres et des nombres pour ne garder que les caractères spéciaux\\033[0m\")\n",
    "text = re.sub('\\w', '', sample_text) \n",
    "text =  re.sub('\\s+',' ', text) #extraspace\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1mSuppression des lettres et des nombres pour ne garder que les caractères spéciaux. \\\n",
    "Les caractères avec les accents apparaissent dans les résultats\\033[0m\")\n",
    "text = re.sub(\"[A-Za-z0-9_]\",'', sample_text) \n",
    "text =  re.sub('\\s+',' ', text) #extraspace\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des mots comprenant à la fois des lettres et des chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des mots comprenant à la fois des caractères en lettre et des chiffres\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple $ ($) ou € (€) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le //, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   ère version était pédagogique, la ème version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des nombres et des mots contenant des nombres avec remplacement du caractère par un espace blanc\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple [SUB]$ ($[SUB]) ou [SUB]€ (€[SUB]) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le [SUB]/[SUB]/[SUB], je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   [SUB] version était pédagogique, la [SUB] version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1mSuppression des mots comprenant à la fois des caractères en lettre et des chiffres\\033[0m\")\n",
    "text = re.sub(r'(\\d+)([a-zA-Z]*)', '', sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1mSuppression des nombres et des mots contenant des nombres avec remplacement du caractère par un espace blanc\\033[0m\")\n",
    "text = re.sub('\\w*\\d\\w*', '[SUB]', sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des majuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des majuscules\u001b[0m\n",
      "l s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en ython dans une utilisation en # (atural anguage rocessing ou traitement automatique du language naturel soit le ). es expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . l suffit de combiner les règles pour arriver à ses fins  . 'est presque magique ! ;-).  défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. epuis le 18/10/2020, je compile les articles sur egex sur le site https://towardsdatascience.com/ ou des bit.ly. n parrallèle, sur le sujet du nlp,  j'utilise le livre de rançois hollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le eep earning pic.twitter.com/xqnp. a   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSuppression des majuscules\\033[0m')\n",
    "text =  re.sub(r'[A-Z]','', sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des caractères hors lettres et nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression de tout sauf les lettres et des nombres\u001b[0m\n",
      "Il s agit d un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en NLP Natural Language Processing ou traitement automatique du language naturel soit le TALN Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100 100 ou 90 90 Il suffit de combiner les règles pour arriver à ses fins C est presque magique A défaut d être compréhensibles à la lecture surtout les regex complexes une regex est une alternative possible lorsque l on souhaite nettoyer des chaines de caractère le vite Depuis le 18 10 2020 je compile les articles sur Regex sur le site https towardsdatascience com ou des bit ly En parrallèle sur le sujet du nlp j utilise le livre de François Chollet fchollet ou f_chollet françois chollet google com sur le Deep Learning pic twitter com DxSqnJPFWp La 1ière version était pédagogique la 2ième version du livre est tout aussi fantastique \n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print(\"\\033[1mSuppression de tout sauf les lettres et des nombres\\033[0m\")\n",
    "text = re.sub(r\"\\W\", \" \", sample_text)\n",
    "text = re.sub('\\s+',' ', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des éléments de ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mTRAITEMENT DE LA PONCTUATION\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mListe par défaut des caractères de punctuation\u001b[0m\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "\n",
      "\n",
      "\u001b[1mUtilisation de la liste par défaut des caractères de punctuation\u001b[0m\n",
      "Il s agit d un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en  NLP  Natural Language Processing ou traitement automatique du language naturel soit le TALN   Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100    100  ou 90€  €90    Il suffit de combiner les règles pour arriver à ses fins    C est presque magique        A défaut d être  compréhensibles à la lecture  surtout les regex complexes   une regex est une alternative  possible  lorsque l on souhaite nettoyer des chaines de caractère le   vite  Depuis le 18 10 2020  je compile les articles sur Regex sur le site https   towardsdatascience com  ou des bit ly  En parrallèle  sur le sujet du nlp   j utilise le livre de François Chollet   fchollet ou f chollet   françois chollet google com  sur le Deep Learning pic twitter com DxSqnJPFWp  La   1ière version était pédagogique  la 2ième version du livre est tout aussi fantastique \n",
      "\n",
      "\n",
      "\u001b[1mUtilisation d'une liste spécifique des caractères de punctuation\u001b[0m\n",
      "Il s agit d un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP  Natural Language Processing ou traitement automatique du language naturel soit le TALN  Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100   100  ou 90€  €90    Il suffit de combiner les règles pour arriver à ses fins    C est presque magique     A défaut d être #compréhensibles à la lecture  surtout les regex complexes  une regex est une alternative  possible  lorsque l on souhaite nettoyer des chaines de caractère le   vite  Depuis le 18 10 2020  je compile les articles sur Regex sur le site https towardsdatascience com  ou des bit ly  En parrallèle  sur le sujet du nlp   j utilise le livre de François Chollet  fchollet ou f chollet   françois chollet google com  sur le Deep Learning pic twitter com DxSqnJPFWp  La   1ière version était pédagogique  la 2ième version du livre est tout aussi fantastique \n",
      "\n",
      "\n",
      "\u001b[1mUtilisation d'une liste adhoc sous la forme d'une classe de caractères\u001b[0m\n",
      "Il s agit d un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN)  Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100  ( 100) ou 90€ (€90)   Il suffit de combiner les règles pour arriver à ses fins    C est presque magique ! ;-)  A défaut d être #compréhensibles à la lecture (surtout les regex complexes)  une regex est une alternative [possible] lorsque l on souhaite nettoyer des chaines de caractère le + vite  Depuis le 18/10/2020  je compile les articles sur Regex sur le site https://towardsdatascience com/ ou des bit ly  En parrallèle  sur le sujet du nlp   j utilise le livre de François Chollet ( fchollet ou f chollet ( françois chollet google com) sur le Deep Learning pic twitter com/DxSqnJPFWp  La   1ière version était pédagogique  la 2ième version du livre est tout aussi fantastique \n",
      "\n",
      "\n",
      "\u001b[1mUtilisation d'une liste qui supprimme les caractères spéciaux sauf accents\u001b[0m\n",
      "Il s agit d un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en  NLP  Natural Language Processing ou traitement automatique du language naturel soit le TALN  Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100   100  ou 90   90    Il suffit de combiner les règles pour arriver à ses fins    C est presque magique     A défaut d être  compréhensibles à la lecture  surtout les regex complexes  une regex est une alternative  possible  lorsque l on souhaite nettoyer des chaines de caractère le   vite  Depuis le 18/10/2020  je compile les articles sur Regex sur le site https //towardsdatascience com/ ou des bit ly  En parrallèle  sur le sujet du nlp   j utilise le livre de François Chollet  fchollet ou f chollet   françois chollet google com  sur le Deep Learning pic twitter com/DxSqnJPFWp  La   1ière version était pédagogique  la 2ième version du livre est tout aussi fantastique \n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "print(\"\\033[1mTRAITEMENT DE LA PONCTUATION\\033[0m\")\n",
    "print(\"\\n\")\n",
    "print('\\033[1mListe par défaut des caractères de punctuation\\033[0m')\n",
    "#supprime l'ensembe des caractères de punctuation  [!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~]\n",
    "print(string.punctuation)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mUtilisation de la liste par défaut des caractères de punctuation\\033[0m')\n",
    "text = re.sub('[%s]' % re.escape(string.punctuation), ' ', sample_text) \n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mUtilisation d\\'une liste spécifique des caractères de punctuation\\033[0m')\n",
    "ma_ponctuation ='!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "text = re.sub('['+ma_ponctuation + ']+', ' ', sample_text) # Comprendre importance du +\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mUtilisation d\\'une liste adhoc sous la forme d\\'une classe de caractères\\033[0m')\n",
    "text = re.sub(r\"[,@\\'?\\.$%_]\", \" \", sample_text, flags=re.I)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mUtilisation d\\'une liste qui supprimme les caractères spéciaux sauf accents\\033[0m') \n",
    "text = re.sub(r'[^ \\nA-Za-z0-9À-ÖØ-öø-ÿЀ-ӿ/]+', ' ', sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des espaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des extra \"white spaces\"\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp, j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La 1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des extra \"white spaces\" au début d'une phrase\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des extra \"white spaces\" à la fin d'une phrase\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90).  Il suffit de combiner les règles pour arriver à ses fins.  C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des doubles \"white spaces\" en un seul\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSuppression des extra \"white spaces\"\\033[0m')\n",
    "text = re.sub(r'\\s+', ' ', sample_text)# matches 1 et inf+ espaces\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression des extra \"white spaces\" au début d\\'une phrase\\033[0m')\n",
    "text = re.sub(r\"^\\s+\", \"\", sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "print('\\033[1mSuppression des extra \"white spaces\" à la fin d\\'une phrase\\033[0m')\n",
    "text = re.sub(r\"\\s+\\.\", \". \", sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "      \n",
    "print('\\033[1mSuppression des doubles \"white spaces\" en un seul\\033[0m')\n",
    "text = re.sub(r'\\n{2,}',' ', sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des éléments inférieurs à x caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des éléments inférieurs à 3 caractères\u001b[0m\n",
      "   'agit  '  texte   test pour mieux comprendreles possibilités des expressions régulières   Python dans une utilisation   #NLP (Natural Language Processing   traitement automatique   language naturel soit   TALN). Les expressions régulières permettent   gérer les lettres ainsi que les chiffres par exemple 100$ ($100)    € (€ ) .   suffit   combiner les règles pour arriver   ses fins  .  'est presque magique ! ;-).   défaut  'être #compréhensibles     lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque  '  souhaite nettoyer des chaines   caractère   + vite. Depuis    / /2020,   compile les articles sur Regex sur   site https://towardsdatascience.com/   des bit. .   parrallèle, sur   sujet   nlp,   'utilise   livre   François Chollet (@fchollet   f_chollet ( françois.chollet@google.com) sur   Deep Learning pic.twitter.com/DxSqnJPFWp.     1ière version était pédagogique,   2ième version   livre est tout aussi fantastique.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSuppression des éléments inférieurs à 3 caractères\\033[0m') \n",
    "# utilisation des ancres + 1 ou 2 caractères comme bornes inférieures et supérieures\n",
    "text = re.sub(r'\\b\\w{1,2}\\b', ' ', sample_text)\n",
    "print(text)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Suppression des urls, hashtags, mentions et adresses email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSupprime une url commençant par https ou http\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site \n",
      "\n",
      "\n",
      "\u001b[1mSupprime une url commençant par https ou http\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSupprimme pic.twitter.com\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSupprimme les adresses mails\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet ou f_chollet ( sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mTest global: traitement simultanée des mentions, hashtags et urls\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet ou f_chollet ( sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mFonctions de nettoyage pour données twitter\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet ( ou f_chollet ( françois.chollet.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSupprime une url commençant par https ou http\\033[0m')\n",
    "text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSupprime une url commençant par https ou http\\033[0m')\n",
    "text = re.sub('http\\S+\\s*', '', sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSupprimme pic.twitter.com\\033[0m')\n",
    "text = re.sub('pic.twitter.com\\S+\\s*','', sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSupprimme les adresses mails\\033[0m')\n",
    "text = re.sub('\\S*@\\S*\\s?','',  sample_text)\n",
    "print(text)\n",
    "#Explication\n",
    "#\\S* : match as many non-space characters you can\n",
    "#@ : then a @\n",
    "#\\S* : then another sequence of non-space characters\n",
    "#s? : And eventually a space, if there is one. Note that the \n",
    "#'?' is needed to match an address at the end of the line. \n",
    "#Because of the greediness of '?', if there is a space, it will always be matched.\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1m' +'Test global: traitement simultanée des mentions, hashtags et urls'+'\\033[0m')\n",
    "text =  re.sub('@(\\w+)| http\\S+\\s* | #(\\w+) | \\S*@\\S*\\s',' ', sample_text) #|[^\\w\\s] \n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1m' +'Fonctions de nettoyage pour données twitter'+'\\033[0m')\n",
    "def remove_users(tweet):\n",
    "    '''Suppression des retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet\n",
    "\n",
    "remove_users(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression du contenu entre deux parenthèses et/ou crochets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression texte entre parenthèses et crochets\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP . Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$  ou 90€  . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture , une regex est une alternative  lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet  sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression texte entre parenthèses\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP . Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ou 90€ . Il suffit de combiner les règles pour arriver à ses fins . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture , une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp, j'utilise le livre de François Chollet sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La 1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression texte entre crochets\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp, j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La 1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression texte entre parenthèses et crochets\\033[0m') \n",
    "text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\",  sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression texte entre parenthèses\\033[0m') \n",
    "text = re.sub(r'\\(.*?\\)', '', sample_text)\n",
    "text = re.sub(r'\\s+', ' ',text)\n",
    "print(text) \n",
    "\n",
    "print(\"\\n\")\n",
    "print('\\033[1mSuppression texte entre crochets\\033[0m')\n",
    "text = re.sub(r'\\[.*?\\]', '', sample_text)\n",
    "text = re.sub(r'\\s+', ' ',text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression sur la base d'un caractère spécial (#, @, etc...)\n",
    "Suppression, suppression du contenu entre deux occurences, suppression avant/après présence du caractère"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression d'un caractère spécial (ici apostrophe)\u001b[0m\n",
      "Il s agit d un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C est presque magique ! ;-). A défaut d être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression d'un caractère spécial + texte attaché(ici #)\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en  (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être  à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression d'un caractère avant le matching spécial + texte attaché(ici \"_\")\u001b[0m\n",
      "_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression d'un caractère spécial (ici \\)\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression d\\'un caractère spécial (ici apostrophe)\\033[0m') \n",
    "text = re.sub(r\"\\'\", \" \", sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression d\\'un caractère spécial + texte attaché(ici #)\\033[0m')\n",
    "text = re.sub(r\"\\#\\w+\", '',  sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression d\\'un caractère avant le matching spécial + texte attaché(ici \"_\")\\033[0m') \n",
    "text = re.sub(r\"^[^_]*\", '',  sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression d\\'un caractère spécial (ici \\)\\033[0m')\n",
    "#text = re.sub(\"\\\\\\\\\", \" \", sample_text)\n",
    "text = re.sub(r\"\\\\\", \" \", sample_text) # ou \n",
    " \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Supprimmer des éléments à partir d'une classe de caractère"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSupprimme les éléments spécifiques à l'aide  d'une classe []\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP Natural Language Processing ou traitement automatique du language naturel soit le TALN Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ $100 ou 90€ €90  Il suffit de combiner les règles pour arriver à ses fins   C'est presque magique  ;- A défaut d'être #compréhensibles à la lecture surtout les regex complexes une regex est une alternative possible lorsque l'on souhaite nettoyer des chaines de caractère le + vite Depuis le 18102020 je compile les articles sur Regex sur le site https:towardsdatasciencecom ou des bitly En parrallèle sur le sujet du nlp  j'utilise le livre de François Chollet @fchollet ou f_chollet  françoischollet@googlecom sur le Deep Learning pictwittercomDxSqnJPFWp La   1ière version était pédagogique la 2ième version du livre est tout aussi fantastique\n",
      "\n",
      "\n",
      "\u001b[1mSupprimme certains éléments présents entre des crochets []\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [SUB] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSupprimme les éléments spécifiques à l\\'aide  d\\'une classe []\\033[0m')\n",
    "text = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"\\.\\[\\]]\", \"\",  sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "print('\\033[1mSupprimme certains éléments présents entre des crochets []\\033[0m')\n",
    "text = re.sub(r'\\[[^\\[\\]]*\\]', '[SUB]',  sample_text) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suppression des éléments en fonction de séquences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des sequences comme [mon texte] ou (https://....)\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des constructions contenant des caractères spéciaux (Ok --> &# !=> #cool)\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mtest\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mSuppression des sequences comme --- or ==\u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "print('\\033[1mSuppression des sequences comme [mon texte] ou (https://....)\\033[0m')\n",
    "text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1',  sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression des constructions contenant des caractères spéciaux (Ok --> &# !=> #cool)\\033[0m')\n",
    "text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ',  sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mtest\\033[0m')\n",
    "text = re.sub(r\"\\&\\S*\\s\", \"\",  sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mSuppression des sequences comme --- or ==\\033[0m')\n",
    "text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ',  sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Suppression d'éléments à partir d'une utilisation simple d'un groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Suppression des mentions, hastags et url \u001b[0m\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet ou f_chollet ( sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m Suppression des mentions, hastags et url \\033[0m')\n",
    "text = re.sub('@[^\\s]+ | http\\S+\\s* | #[^\\s]+ | \\S*@\\S*\\s',' ', sample_text, flags = re.UNICODE)\n",
    "print(text)\n",
    "print(\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Extraction de caractère spécifiques** <a id='extractioncaractères'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction d'éléments en fonction de la longueur du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des mots qui ont une longueur de caractères supérieure à 3\u001b[0m\n",
      "['agit', 'texte', 'test', 'pour', 'mieux', 'comprendreles', 'possibilités', 'des', 'expressions', 'régulières', 'Python', 'dans', 'une', 'utilisation', 'NLP', 'Natural', 'Language', 'Processing', 'traitement', 'automatique', 'language', 'naturel', 'soit', 'TALN', 'Les', 'expressions', 'régulières', 'permettent', 'gérer', 'les', 'lettres', 'ainsi', 'que', 'les', 'chiffres', 'par', 'exemple', '100', '100', 'suffit', 'combiner', 'les', 'règles', 'pour', 'arriver', 'ses', 'fins', 'est', 'presque', 'magique', 'défaut', 'être', 'compréhensibles', 'lecture', 'surtout', 'les', 'regex', 'complexes', 'une', 'regex', 'est', 'une', 'alternative', 'possible', 'lorsque', 'souhaite', 'nettoyer', 'des', 'chaines', 'caractère', 'vite', 'Depuis', '2020', 'compile', 'les', 'articles', 'sur', 'Regex', 'sur', 'site', 'https', 'towardsdatascience', 'com', 'des', 'bit', 'parrallèle', 'sur', 'sujet', 'nlp', 'utilise', 'livre', 'François', 'Chollet', 'fchollet', 'f_chollet', 'françois', 'chollet', 'google', 'com', 'sur', 'Deep', 'Learning', 'pic', 'twitter', 'com', 'DxSqnJPFWp', '1ière', 'version', 'était', 'pédagogique', '2ième', 'version', 'livre', 'est', 'tout', 'aussi', 'fantastique']\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des mots qui ont une longueur de caractères supérieure à 3 et inférieure à 8 caractère\u001b[0m\n",
      "['agit', 'texte', 'test', 'pour', 'mieux', 'comprend', 'reles', 'possibil', 'ités', 'des', 'expressi', 'ons', 'régulièr', 'Python', 'dans', 'une', 'utilisat', 'ion', 'NLP', 'Natural', 'Language', 'Processi', 'traiteme', 'automati', 'que', 'language', 'naturel', 'soit', 'TALN', 'Les', 'expressi', 'ons', 'régulièr', 'permette', 'gérer', 'les', 'lettres', 'ainsi', 'que', 'les', 'chiffres', 'par', 'exemple', '100', '100', 'suffit', 'combiner', 'les', 'règles', 'pour', 'arriver', 'ses', 'fins', 'est', 'presque', 'magique', 'défaut', 'être', 'compréhe', 'nsibles', 'lecture', 'surtout', 'les', 'regex', 'complexe', 'une', 'regex', 'est', 'une', 'alternat', 'ive', 'possible', 'lorsque', 'souhaite', 'nettoyer', 'des', 'chaines', 'caractèr', 'vite', 'Depuis', '2020', 'compile', 'les', 'articles', 'sur', 'Regex', 'sur', 'site', 'https', 'towardsd', 'atascien', 'com', 'des', 'bit', 'parrallè', 'sur', 'sujet', 'nlp', 'utilise', 'livre', 'François', 'Chollet', 'fchollet', 'f_cholle', 'françois', 'chollet', 'google', 'com', 'sur', 'Deep', 'Learning', 'pic', 'twitter', 'com', 'DxSqnJPF', '1ière', 'version', 'était', 'pédagogi', 'que', '2ième', 'version', 'livre', 'est', 'tout', 'aussi', 'fantasti', 'que']\n",
      "\n",
      "\n",
      "\u001b[1mExtracton des mots qui ont une longueur de caractère inférieure à 8 caractères\u001b[0m\n",
      "['Il', '', 's', '', 'agit', '', 'd', '', 'un', '', 'texte', '', 'de', '', 'test', '', 'pour', '', 'mieux', '', 'comprend', 'reles', '', 'possibil', 'ités', '', 'des', '', 'expressi', 'ons', '', 'régulièr', 'es', '', 'en', '', 'Python', '', 'dans', '', 'une', '', 'utilisat', 'ion', '', 'en', '', '', 'NLP', '', '', 'Natural', '', 'Language', '', 'Processi', 'ng', '', 'ou', '', 'traiteme', 'nt', '', 'automati', 'que', '', 'du', '', 'language', '', 'naturel', '', 'soit', '', 'le', '', 'TALN', '', '', '', 'Les', '', 'expressi', 'ons', '', 'régulièr', 'es', '', 'permette', 'nt', '', 'de', '', 'gérer', '', 'les', '', 'lettres', '', 'ainsi', '', 'que', '', 'les', '', 'chiffres', '', 'par', '', 'exemple', '', '100', '', '', '', '', '100', '', '', 'ou', '', '90', '', '', '', '', '90', '', '', '', '', 'Il', '', 'suffit', '', 'de', '', 'combiner', '', 'les', '', 'règles', '', 'pour', '', 'arriver', '', 'à', '', 'ses', '', 'fins', '', '', '', '', 'C', '', 'est', '', 'presque', '', 'magique', '', '', '', '', '', '', '', '', 'A', '', 'défaut', '', 'd', '', 'être', '', '', 'compréhe', 'nsibles', '', 'à', '', 'la', '', 'lecture', '', '', 'surtout', '', 'les', '', 'regex', '', 'complexe', 's', '', '', '', 'une', '', 'regex', '', 'est', '', 'une', '', 'alternat', 'ive', '', '', 'possible', '', '', 'lorsque', '', 'l', '', 'on', '', 'souhaite', '', 'nettoyer', '', 'des', '', 'chaines', '', 'de', '', 'caractèr', 'e', '', 'le', '', '', '', 'vite', '', '', 'Depuis', '', 'le', '', '18', '', '10', '', '2020', '', '', 'je', '', 'compile', '', 'les', '', 'articles', '', 'sur', '', 'Regex', '', 'sur', '', 'le', '', 'site', '', 'https', '', '', '', 'towardsd', 'atascien', 'ce', '', 'com', '', '', 'ou', '', 'des', '', 'bit', '', 'ly', '', '', 'En', '', 'parrallè', 'le', '', '', 'sur', '', 'le', '', 'sujet', '', 'du', '', 'nlp', '', '', '', 'j', '', 'utilise', '', 'le', '', 'livre', '', 'de', '', 'François', '', 'Chollet', '', '', '', 'fchollet', '', 'ou', '', 'f_cholle', 't', '', '', '', 'françois', '', 'chollet', '', 'google', '', 'com', '', '', 'sur', '', 'le', '', 'Deep', '', 'Learning', '', 'pic', '', 'twitter', '', 'com', '', 'DxSqnJPF', 'Wp', '', '', 'La', '', '', '', '1ière', '', 'version', '', 'était', '', 'pédagogi', 'que', '', '', 'la', '', '2ième', '', 'version', '', 'du', '', 'livre', '', 'est', '', 'tout', '', 'aussi', '', 'fantasti', 'que', '', '']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mExtraction des mots qui ont une longueur de caractères supérieure à 3\\033[0m')\n",
    "# borne inférieure ->3, pas de limite supérieure\n",
    "text = re.findall('\\w{3,}', sample_text) \n",
    "print(text)\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mExtraction des mots qui ont une longueur de caractères supérieure à 3 et inférieure à 8 caractère\\033[0m')\n",
    "# borne inférieure ->3, pas de limite supérieure\n",
    "text = re.findall('\\w{3,8}', sample_text) \n",
    "print(text)\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mExtracton des mots qui ont une longueur de caractère inférieure à 8 caractères\\033[0m')\n",
    "# utilisation des ancres + 1 ou 2 caractères comme bornes inférieures et supérieures\n",
    "text = re.findall('\\w{,8}', sample_text) \n",
    "print(text)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction d'éléments avec re.search et re.findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des hashtags\u001b[0m\n",
      "['#NLP', '#compr']\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des hashtags sans le terme #\u001b[0m\n",
      "['NLP', 'compréhensibles']\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des hashtags sans le terme #\u001b[0m\n",
      "['NLP', 'compréhensibles']\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des hashtags sans le terme #\u001b[0m\n",
      "<regex.Match object; span=(128, 132), match='#NLP'>\n",
      "<regex.Match object; span=(449, 465), match='#compréhensibles'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mExtraction des hashtags\\033[0m')\n",
    "text = re.findall('(#[A-Za-z0-9-_]+)', sample_text)  \n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "print('\\033[1mExtraction des hashtags sans le terme #\\033[0m')\n",
    "text = re.findall(r'(?<=#)\\w+', sample_text) #lookahead\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "print('\\033[1mExtraction des hashtags sans le terme #\\033[0m')\n",
    "text = re.findall(r'#(\\w+)', sample_text)  \n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "print('\\033[1mExtraction des hashtags sans le terme #\\033[0m')\n",
    "for i in re.finditer(r'#(\\w+)', sample_text):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction d'éléments à partir d'une utilisation simple d'un groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des mentions\u001b[0m\n",
      "['@fchollet', '@google']\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des mentions sans le caractère @\u001b[0m\n",
      "['fchollet', 'google']\n",
      "\u001b[1mExtraction des mentions\u001b[0m\n",
      "['#NLP', '#compr']\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des hashtags sans le caractère #\u001b[0m\n",
      "['NLP', 'compréhensibles']\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des hashtags sans le caractère #\u001b[0m\n",
      "['NLP', 'compréhensibles']\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mExtraction des mentions\\033[0m')\n",
    "text = re.findall('(@[A-Za-z]+[A-Za-z0-9-_]+)', sample_text)  \n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mExtraction des mentions sans le caractère @\\033[0m')\n",
    "text = re.findall(r'(?<=@)\\w+', sample_text)\n",
    "print(text)\n",
    "\n",
    "print('\\033[1mExtraction des mentions\\033[0m')\n",
    "text = re.findall('(#[A-Za-z]+[A-Za-z0-9-_]+)', sample_text)  \n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('\\033[1mExtraction des hashtags sans le caractère #\\033[0m')\n",
    "text = re.findall(r'(?<=#)\\w+', sample_text)\n",
    "print(text)\n",
    "\n",
    "print(\"\\n\")  \n",
    "print('\\033[1mExtraction des hashtags sans le caractère #\\033[0m')\n",
    "#re.findall(r'(?i)\\#\\w+', sample_text) # avec #\n",
    "text = re.findall(r'(?i)(?<=\\#)\\w+', sample_text) # sans #\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction adresse mail et séparation des éléments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des adresses mail\u001b[0m\n",
      "['françois.chollet@google.com']\n",
      "\u001b[1mExtraction adresse mail\u001b[0m\n",
      "Adresse email: françois.chollet@google.com\n",
      "Username: françois.chollet\n",
      "Hébergeur: google.com\n",
      "\n",
      "\n",
      "\u001b[1mExtraction adresse mail (méthode classe)\u001b[0m\n",
      "Adresse email: françois.chollet@google.com\n",
      "Username: françois.chollet\n",
      "Hébergeur: google.com\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1m' +'Extraction des adresses mail' + '\\033[0m')\n",
    "text = re.findall(r'[\\w\\.]+@[\\w\\.]+',str(sample_text))\n",
    "print(text)\n",
    "\n",
    "print('\\033[1m' +'Extraction adresse mail' + '\\033[0m')\n",
    "match = re.search(r'([\\w\\.-]+)@([\\w\\.-]+)', sample_text)\n",
    "if sample_text:\n",
    "    print(\"Adresse email:\", match.group()) # Adresse complète\n",
    "    print(\"Username:\", match.group(1)) # Username (groupe 1)\n",
    "    print(\"Hébergeur:\", match.group(2)) # Hébergeur (groupe 2)\n",
    "print(\"\\n\") \n",
    "\n",
    "print('\\033[1m' +'Extraction adresse mail (méthode classe)' + '\\033[0m')     \n",
    "match = re.search(r'(?P<email>(?P<username>[\\w\\.-]+)@(?P<host>[\\w\\.-]+))', sample_text)\n",
    "if sample_text:\n",
    "    print(\"Adresse email:\", match.group('email')) # Adresse complète\n",
    "    print(\"Username:\", match.group('username')) # Username (groupe 1)\n",
    "    print(\"Hébergeur:\", match.group('host')) # Hébergeur (groupe 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mExtraction des adresses mail\u001b[0m\n",
      "['Il', 'Python', 'NLP', 'Natural', 'Language', 'Processing', 'TALN', 'Les', 'Il', 'Depuis', 'Regex', 'En', 'François', 'Chollet', 'Deep', 'Learning', 'DxSqnJPFWp', 'La']\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1m' +'Extraction des adresses mail' + '\\033[0m')\n",
    "\n",
    "text = re.findall(r'\\b[A-Z]\\w+',  sample_text) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mUtilisation du wild character \".\"\u001b[0m\n",
      "['NLP']\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mUtilisation du wild character \".\"\\033[0m')\n",
    "text = re.findall(r'N.P', sample_text) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Extraire un des caractères spécifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mTrouver un caractère spécial ici \"C\"\u001b[0m\n",
      "['C', 'C']\n",
      "\n",
      "\n",
      "\u001b[1mTrouver un caractère spécial ici \".\"\u001b[0m\n",
      "['.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "\n",
      "\n",
      "\u001b[1mTrouver un caractère spécial ici \"0-9\"\u001b[0m\n",
      "['100', '100', '90', '90', '18', '10', '2020', '1', '2']\n",
      "\n",
      "\n",
      "\u001b[1mTrouver un caractère spécial ici \"0-6\"\u001b[0m\n",
      "['1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '2', '0', '2', '0', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mTrouver un caractère spécial ici \"C\"\\033[0m')\n",
    "text = re.findall(r'C', sample_text) \n",
    "print(text)\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mTrouver un caractère spécial ici \".\"\\033[0m')\n",
    "text = re.findall(r'\\.', sample_text) \n",
    "print(text)\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mTrouver un caractère spécial ici \"0-9\"\\033[0m')\n",
    "text = re.findall(r'[0-9]+', sample_text)\n",
    "print(text)\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mTrouver un caractère spécial ici \"0-6\"\\033[0m')\n",
    "text = re.findall(r'[0-6]', sample_text) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction d'une date\n",
    "- En fonction du format de la date, il est nécessaire de modifier la regex. Deux stratégies sont possibles. Soit écrire une regex \"réduite\" qui permettra de traiter des cas spécifiques (hypothèse que les dates sont similaires dans les documents qunat à leur formatage) ou développer des regex \"développées\" capables de gérer différents formatage de date (ex mm/dd/aaaa, dd/mm/aaaa, dd-mm-aaaa, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Utilisation d'un pattern simple pour extraire une date\u001b[0m\n",
      "['18/10/2020']\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m Utilisation d\\'un pattern simple pour extraire une date\\033[0m')\n",
    "text = re.findall(r'\\d{1,2}\\/\\d{1,2}\\/\\d{4}', sample_text) #re.findall('\\d{2}[ |,][a-z]{3}[ |,]\\d{4}',date)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "Pattern plus élaboré\n",
      "<regex.Match object; span=(628, 638), match='18/10/2020'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "print('Pattern plus élaboré')\n",
    "text = re.search(r'(\\d+(/|-){1}\\d+(/|-){1}\\d{2,4})', sample_text)\n",
    "#text = re.findall(r'(^(0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])[- /.](19|20)\\d\\d$)', sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mExtraction de l'année\u001b[0m\n",
      "<regex.Match object; span=(628, 638), match='18/10/2020'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "print('\\033[1mExtraction de l\\'année\\033[0m')\n",
    "text = re.search(r'([0-9]|1[0-9]|2[0-9]|3[0-5])/([0-9]|1[0-9]|2[0-9]|3[0-5])/([0-9][0-9][0-9][0-9])', sample_text)\n",
    "print(text)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction d'éléments sur la base d'un mot clé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mPattern simple\u001b[0m\n",
      "[\"Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN)\"]\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "print('\\033[1mPattern simple\\033[0m')\n",
    "keyword = \"NLP\"    \n",
    "text = re.findall(r'([^.]*'+keyword+'[^.]*)', sample_text)  \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extaire les chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "\u001b[1mAfficher seulement les chiffres\u001b[0m\n",
      "['100', '100', '90', '90', '18', '10', '2020']\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mAfficher seulement les chiffres\\033[0m')\n",
    "text = re.findall(r'\\b\\d+\\b', sample_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Correction des chaines de caractères** <a id='correction'></a>\n",
    "- Quelques regex visant à corriger répétitions de mots, de phrases ou erreurs de frappe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_text = \"J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnent\\\n",
    "d'un vrai travail de vulgarisation à destination des practiciens de la data !!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insérer un espace après un point si inexistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mInsérer un espace après un point si inexistant\u001b[0m\n",
      "J'aime travailler suuur le NLP. J'aime travailler suur le NLP.  Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mInsérer un espace après un point si inexistant\\033[0m')\n",
    "def corr(s):\n",
    "    return re.sub(r'\\.(?!\\r)', '. ', re.sub(r' +', ' ', s))\n",
    "\n",
    "print(corr(mon_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insérer un espace et un point avant une lettre majuscule identifiée dans un mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mInsérer un espace et un point avant une lettre majuscule identifiée dans un mot\u001b[0m\n",
      "J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières années. Heureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mInsérer un espace et un point avant une lettre majuscule identifiée dans un mot\\033[0m')\n",
    "\n",
    "text =  re.sub(r'([a-z])([A-Z])', r'\\1. \\2', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insérer un espace avant et après un mot en majuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mInsérer un espace avant et après un mot en majuscule\u001b[0m\n",
      " J 'aime travailler suuur le  NLP . J 'aime travailler suur le  NLP . Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mInsérer un espace avant et après un mot en majuscule\\033[0m')\n",
    "\n",
    "text = re.sub(r'\\b([A-Z]+(?:\\s+[A-Z]+)*)\\b', r' \\1 ', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supprimmer les erreurs de frappe provenant des répétitions de même caractère"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mSupprimmer les erreurs de frappe provenant des répétitions de même caractère\u001b[0m\n",
      "J'aime travailler sur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}') #problème sup à 3\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSupprimmer les erreurs de frappe provenant des répétitions de même caractère\\033[0m')\n",
    "text =  re.sub(r'([a-z])\\1{2,}', r'\\1', mon_text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supprimmer les erreurs de frappe provenant des répétitions d'un caractère de ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mSupprimmer les répétitions de caractère de ponctuation(erreur de frappe)\u001b[0m\n",
      "J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSupprimmer les répétitions de caractère de ponctuation(erreur de frappe)\\033[0m')\n",
    "text =  re.sub(r'([\\W+])\\1{1,}', r'\\1',mon_text) \n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supprimmer une phrase en répétition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mSupprimmer une phrase en répétition\u001b[0m\n",
      "J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSupprimmer une phrase en répétition\\033[0m')\n",
    "text =  re.sub(r'(.{2,}?)\\1{1,}', r'\\1', mon_text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mSupprimmer le texte et tout ce qui suit ensuite\u001b[0m\n",
      "J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de \n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSupprimmer le texte et tout ce qui suit ensuite\\033[0m') \n",
    "text =  re.sub(r'ces dernières annéesHeureusement, ces[.|\\.|! ].+', '', mon_text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supprimmer un mot sur la base d'une regex\n",
    "- Utilisation par exemple pour supprimmer une famille de mots ayant la même racine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "\u001b[1mSupprimmer le texte matchant une regex\u001b[0m\n",
      "J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les  s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mSupprimmer le texte matchant une regex\\033[0m') \n",
    "text =  re.sub(r'(pr(\\s-\\s)?.*ès)', '', mon_text)\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Regex spécifiques avec re.search** <a id='regexspecifiques'></a>\n",
    "- Regex spécifiques autour de la recherche d'éléments (re.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "<regex.Match object; span=(28, 30), match='LP'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "text =  re.search(r'L[PN]', mon_text)\n",
    "print(text) # seulement premier résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction des majuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "JNLPJNLPLH\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "text =  re.sub(r'[^A-Z]','', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "J'    NLP.J'    NLP. L è  éé   2021 à '   è éH,  è ''     à       !!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "text =  re.sub(r'[a-z]','', mon_text)\n",
    "print(text)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en  à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "text =  re.sub(r'[0-9]','', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "'    .'    .  è  éé    à '   è é,  è ''     à       !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "text =  re.sub(r'[a-zA-Z0-9-_]','', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data   \n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "text =  re.sub(r'[NLP]*[\\s!]',' ', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "J'aime travailler  uuur le NLP.J'aime travailler  uur le NLP. Le  progrè  ont été fulgurant  en 2021 à l'image de ce  dernière  année Heureu ement, ce  progrè   'accompagnentd'un vrai travail de vulgari ation à de tination de  practicien  de la data !!\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "text =  re.sub(r'[Ss]',' ', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " J'aime travailler suuur le NLP.J'aime travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n",
      "\n",
      "\n",
      "J'e travailler suuur le NLP.J'e travailler suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Texte original ---- \\n {mon_text}')\n",
    "print('\\n')\n",
    "\n",
    "text =  re.sub(r'a.m','', mon_text) #. n'importe quel caractère entre a et m\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J' trav suuur le NLP.J' trav suur le NLP. Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrtravail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "text =  re.sub(r'ai(me|ller| )','', mon_text) #ai + me ou lller --> matching aime et travailler\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'aime travailler suuur le .J'aime travailler suur le . Les progrès ont été fulgurants en 2021 à l'image de ces dernières annéesHeureusement, ces progrès s'accompagnentd'un vrai travail de vulgarisation à destination des practiciens de la data !!\n"
     ]
    }
   ],
   "source": [
    "text =  re.sub(r'[nN]LP','', mon_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Autres exemples** <a id='divers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Compter le nombre de mots d'une phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original ---- \n",
      " Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "print(f'Texte original ---- \\n {sample_text}')\n",
    "print(\"\\n\")\n",
    "def compte_mot (x): \n",
    "    count = len(re.findall(r'\\w+', x))\n",
    "    return (count)\n",
    "\n",
    "count = len(re.findall(r'\\w+',  sample_text))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Répétition regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  x-x        None\n",
      "2  x--x       <regex.Match object; span=(0, 4), match='x--x'>\n",
      "3  x---x      <regex.Match object; span=(0, 5), match='x---x'>\n",
      "4  x----x     <regex.Match object; span=(0, 6), match='x----x'>\n",
      "5  x-----x    None\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    s = f\"x{'-' * i}x\"\n",
    "    print(f'{i}  {s:10}', re.search('x-{2,4}x', s))# recherche répétitions de - entre deux et quatre fois  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  x-x        <regex.Match object; span=(0, 3), match='x-x'>\n",
      "2  x--x       <regex.Match object; span=(0, 4), match='x--x'>\n",
      "3  x---x      <regex.Match object; span=(0, 5), match='x---x'>\n",
      "4  x----x     <regex.Match object; span=(0, 6), match='x----x'>\n",
      "5  x-----x    None\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    s = f\"x{'-' * i}x\"\n",
    "    print(f'{i}  {s:10}', re.search('x-{,4}x', s)) # recherche répétitions au max quatre fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  x-x        None\n",
      "2  x--x       None\n",
      "3  x---x      <regex.Match object; span=(0, 5), match='x---x'>\n",
      "4  x----x     <regex.Match object; span=(0, 6), match='x----x'>\n",
      "5  x-----x    <regex.Match object; span=(0, 7), match='x-----x'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    s = f\"x{'-' * i}x\"\n",
    "    print(f'{i}  {s:10}', re.search('x-{3,}x', s))# recherche répétitions au min deux fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  x-x        <regex.Match object; span=(0, 3), match='x-x'>\n",
      "2  x--x       <regex.Match object; span=(0, 4), match='x--x'>\n",
      "3  x---x      <regex.Match object; span=(0, 5), match='x---x'>\n",
      "4  x----x     <regex.Match object; span=(0, 6), match='x----x'>\n",
      "5  x-----x    <regex.Match object; span=(0, 7), match='x-----x'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    s = f\"x{'-' * i}x\"\n",
    "    print(f'{i}  {s:10}', re.search('x-{,}x', s))# pas de condition min ou max "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilisation d'un groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation simple d'un groupe\n",
      "Il s'agit d'un [SUB]x[SUB] de [SUB]st pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #NLP (Natural Language Processing ou trai[SUB]ment automatique du language naturel soit le TALN). Les expressions régulières permet[SUB]nt de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une al[SUB]rnative [possible] lorsque l'on souhai[SUB] nettoyer des chaines de caractère le + vi[SUB]. Depuis le 18/10/2020, je compile les articles sur Regex sur le si[SUB] https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twit[SUB]r.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "Utilisation simple d'un groupe\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #[SUB] (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "Solution alternative sans création d'un groupe\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #[SUB] (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n",
      "\n",
      "\n",
      "Utilisation simple d'un groupe + recherche de répétitions\n",
      "Il s'agit d'un texte de test pour mieux comprendreles possibilités des expressions régulières en Python dans une utilisation en #[SUB] (Natural Language Processing ou traitement automatique du language naturel soit le TALN). Les expressions régulières permettent de gérer les lettres ainsi que les chiffres par exemple 100$ ($100) ou 90€ (€90) . Il suffit de combiner les règles pour arriver à ses fins  . C'est presque magique ! ;-). A défaut d'être #compréhensibles à la lecture (surtout les regex complexes), une regex est une alternative [possible] lorsque l'on souhaite nettoyer des chaines de caractère le + vite. Depuis le 18/10/2020, je compile les articles sur Regex sur le site https://towardsdatascience.com/ ou des bit.ly. En parrallèle, sur le sujet du nlp,  j'utilise le livre de François Chollet (@fchollet ou f_chollet ( françois.chollet@google.com) sur le Deep Learning pic.twitter.com/DxSqnJPFWp. La   1ière version était pédagogique, la 2ième version du livre est tout aussi fantastique.\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "print(\"Utilisation simple d'un groupe\")\n",
    "  \n",
    "text = re.sub(r'(te)', '[SUB]', sample_text) #\n",
    "print(text)\n",
    "print(\"\\n\")  \n",
    "print(\"Utilisation simple d'un groupe\") \n",
    "text = re.sub(r'(NLP)', '[SUB]', sample_text) # X patterns ==> X sub\n",
    "print(text)\n",
    "print(\"\\n\")  \n",
    "print(\"Solution alternative sans création d'un groupe\")\n",
    " \n",
    "text = re.sub('NLP+', '[SUB]', sample_text)  # X patterns ==> 1 sub\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Utilisation simple d'un groupe + recherche de répétitions\")\n",
    "\n",
    "text = re.sub(r'(NLP)+', '[SUB]', sample_text)  # X patterns ==> 1 sub\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
